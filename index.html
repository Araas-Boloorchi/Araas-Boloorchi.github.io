<!DOCTYPE HTML>
<html>
  <head>
    <!-- Google Analytics Tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-STGLQW4BJX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-STGLQW4BJX');
    </script>

    <!-- Title -->
    <title>Araas (Habib) Boloorchi</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Isotope JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css2?family=Asap:wght@100;200;300;400;500;600;700&display=swap" rel="stylesheet">

    <!-- Additional Styles for Custom Formatting -->
    <style>
      .skills {
        color: grey;
      }
      .job-title {
        font-weight: bold;
      }
      .company-name {
        font-weight: bold;
      }

      /* Make the videos bigger (1.5×) */
      .list-item.highlight.previews {
        display: flex;       /* Place videos in a row */
        gap: 2rem;          /* Add space between them */
        justify-content: center;
        align-items: center;
        flex-wrap: wrap;    /* Wrap to the next line if needed */
      }
      .preview1, .preview2, .preview3 {
        transform: scale(1);      /* Scale the video to 1.5× */
        transform-origin: center;   /* Scale from the center */
      }
    </style>
  </head>

  <body id="body">

    <div id="main">
      <div id="intro">
        <div id="intro-text">
          <h1>Araas Boloorchi</h1>
          <p>
            I'm a Ph.D. candidate in Computer Science at Oklahoma State University. I am a researcher and machine learning expert focused on deep learning model architecture for industry and academia, specializing in computer vision, large language models, robotics, and IoT, with machine learning and data science expertise.
            <div id="more-bio" style="display: none;">
              <br>
              <p>Araas Boloorchi's journey in technology began in high school, where he focused on math and physics. His passion for innovation led him to the University of Science and Culture, where he pursued a degree in software engineering. In his first year, Araas began exploring the world of humanoid robots, utilizing mobile phones as a platform. This early experience sparked his interest in artificial intelligence and machine learning.

During his undergraduate years, Araas formed a team that participated in numerous competitions. One notable achievement was securing third place in an AI irregular gesture recognition competition using surveillance cameras. The challenge involved detecting fights, thrown objects, and left baggage. Araas's team also competed in various robotics contests, where he took on the role of a mentor, teaching his team machine learning techniques.

After earning his bachelor's degree, Araas pursued a master's degree at the University of Qazvin in Artificial Intelligence and Robotics, where he joined the MRL team in the Standard Platform League, focusing on NAO robots. His interest in cognitive science and the dream of robot's selfawareness led him to work in a cognitive systems lab, delving into EEG and cognitive science.

Araas's academic journey then took him to the United States, where he joined Oklahoma State University for a direct Ph.D. program. At OSU, he became a Graduate Teaching Assistant in his first year, sharing his knowledge and expertise with students. He then joined the Advanced Tech Research Center, focusing on Simultaneous Localization and Mapping (SLAM) and visual-inertial odometry. His work involved developing hardware with Raspberry Pi, cameras, and IMU, and was funded by the Air Force Institute.

Following his time at the ATRC, Araas worked in the Cyber-Physical Lab, where he utilized Unity and SolidWorks to create CAD models, virtual relity and Augmented reality. He also interned at Baker Hughes, a General Electric company, PwC, and Sanborn, gaining valuable industry experience.

Throughout his time at OSU, Araas continued to serve as a TA, sharing his knowledge in courses related to programming languages and computer science. He later joined the i-LEAD lab, focusing on explainable AI and computer vision. His research on visual-inertial odometry for low-cost devices culminated

in a published paper titled "Brain-Inspired Visual Odometry: Balancing Speed and Interpretability through a System of Systems Approach." This work exemplifies Araas's commitment to advancing AI technology while ensuring practical applications and interpretability.

Araas's diverse experiences have equipped him with a robust skill set in machine learning, robotics, computer vision, and software engineering. His journey reflects a continuous pursuit of knowledge and innovation, with a vision to bridge the gap between cutting-edge technology and real-world applications.</p>
            </div>
            <br>
            <a href="javascript:toggle_bio()">Formal Bio</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/Araas-Boloorchi">GitHub</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?user=0oXdUkAAAAAJ&hl=en">Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/Araas-boloorchi">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <br><br>
            hboloor at okstate dot edu
            <br><br>
          </p>
        </div>
        <div id="intro-image">
          <img src="images/profile.jpg" alt="Araas Boloorchi">
        </div>
      </div>

      <!-- Filters Section -->
      <div id="filters" class="button-group">
        <button class="button is-checked" data-filter=".highlight">Highlights</button>
        <button class="button" data-filter=".publication">Research</button>
        <button class="button" data-filter=".award">Awards & Scholarships</button>
        <button class="button" data-filter=".work-experience">Work Experience</button>
      </div>

      <!-- Grid Section -->
      <div class="grid">
        <!-- Highlights Section -->
        <div class="list-item highlight description" data-category="highlight">
          When a robot moves or an AI project works something in my heart falls down:
        </div>

        <div class="list-item highlight previews" data-category="highlight">
          <video class="preview1" playsinline muted autoplay loop>
            <source src="images/VIO.mp4" type="video/mp4">
          </video>
          <video class="preview2" playsinline muted autoplay loop>
            <source src="images/Nao_Self_Calibration.mp4" type="video/mp4">
          </video>
          <video class="preview3" playsinline muted autoplay loop>
            <source src="images/Arm_Robot.mp4" type="video/mp4">
          </video>
        </div>
        <div class="list-item highlight" data-category="highlight">
          <h3>SightVoice</h3>
          <p>
            SightVoice is a platform that leverages computer vision and deep learning to assist visually impaired individuals in real-time, offering audio feedback on the user’s surroundings and helping them navigate the world more independently.
          </p>
          <img src="images/sightvoice.jpg" alt="SightVoice Demo" style="max-width: 100%; height: auto;">
        </div>

        <!-- Publications Section -->
        <div class="list-item publication project-description" data-category="publication">
          <h3><a href="https://link.springer.com/article/10.1186/s42467-024-00016-5">Towards responsible AI: an implementable blueprint for integrating explainability and social-cognitive frameworks in AI systems</a></h3>
          <p>Rittika Shamsuddin, Araas Boloorchi, Pavan R. Gottimukkula</p>
        </div>
        <div class="list-item publication project-description" data-category="publication">
          <h3><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0oXdUkAAAAAJ&citation_for_view=0oXdUkAAAAAJ:9yKSN-GCB0IC">Brain-Inspired Visual Odometry: Balancing Speed and Interpretability through a System of Systems Approach</a></h3>
          <p>Araas Boloorchi Tabrizi, Christopher Crick</p>
        </div>
        
        <div class="list-item publication project-description" data-category="publication">
          <h3><a href="https://ieeexplore.ieee.org/abstract/document/10385640">Enhancing ProteinBERT: Integrating Intrinsically Disordered Proteins for Comprehensive Proteomic Predictions</a></h3>
          <p>Jewelle D. Stone, Araas Boloorchi Tabrizi, Rittika Shamsuddin</p>
        </div>

        <!-- Awards Section -->
        <div class="list-item award project-description" data-category="award">
          <ul>
            <li>
              <h3>Health AI Bias Summer School and Datathon Scholarship</h3>
              <p>August 2024</p>
            </li>
            <li>
              <h3>Scholarships for I-corps Workshops (Two Ideas)</h3>
              <p>June & July 2024</p>
            </li>
            <li>
              <h3>3-time Finalist - Business Plan Competition, Spears School of Business</h3>
              <p>Feb 2022, 2023, 2024</p>
            </li>
            <li>
              <h3>Champion - International Student Art Performance Competition at OSU</h3>
              <p>Nov 2022</p>
            </li>
            <li>
              <h3>Creativity, Innovation, and Entrepreneurship Scholarship</h3>
              <p>Dec 2021</p>
            </li>
            <li>
              <h3>1st Place - Innovative Idea in Automation and Transportation Competition</h3>
              <p>April 2018</p>
            </li>
            <li>
              <h3>1st Place - Open International Robotics League (Soccer) Technical Competition</h3>
              <p>April 2016</p>
            </li>
            <li>
              <h3>Finalist - Machine Vision for Irregular Gesture Recognition Competition, AUT Cop</h3> 
              <p>Sept 2013</p>
            </li>
          </ul>
        </div>

        <!-- Work Experience Section -->
        <div class="list-item work-experience project-description" data-category="work-experience">
          <h2>Work Experience</h2>
          
          <!-- ILead Laboratory -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>ILead Laboratory – Stillwater, OK</strong></h4>
            <span>May 2023 - May 2024</span>
            <ul>
              <li>Designed and developed an explainable deep model for describing visual charts with 87% precision via fine-tuned GPT-3.5, based on CNN, graph learning, and DNN, which we are submitting to the PAMI 2024 Journal.</li>
              <li>Improved 7% Breast Cancer Detection Datathon in X-ray in a multidisciplinary team with 9 members.</li>
              <li class="skills"><strong>Skills and Languages:</strong> PyTorch, TensorFlow, Keras, GNN, CNN, LLM, BERT, GAN, Fine-Tuning</li>
            </ul>
          </div>

          <!-- Sanborn -->
          <div class="job">
            <h3 class="job-title"><strong>Deep Learning and Computer Vision Engineer</strong></h3>
            <h4 class="company-name"><strong>Sanborn - Colorado Springs, CO</strong></h4>
            <span>May - August 2022</span>
            <ul>
              <li>Implemented and trained a new depth estimation approach with a 150 GB high-quality image dataset.</li>
              <li>Enhanced the CNN models to process full HD images with a 15% reduction in complexity.</li>
              <li class="skills"><strong>Skills and Languages:</strong> PyTorch, Keras, Python, CNN, Photogrammetry, Image Processing, Fine-Tuning</li>
            </ul>
          </div>

          <!-- PricewaterhouseCoopers (PwC) -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>PricewaterhouseCoopers (PwC) - Dallas, TX</strong></h4>
            <span>May - August 2020</span>
            <ul>
              <li>Re-engineered and tailored a data visualization tool in 20% less than estimated time with a team of 5.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Tableau, PySpark, Scala, AWS, Microsoft Azure, Jira, Random Forest, SAS</li>
            </ul>
          </div>

          <!-- General Electric -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Vision and Deep Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>General Electric - Oklahoma City, OK</strong></h4>
            <span>May - August 2019</span>
            <ul>
              <li>Developed a machine vision application to analyze drill bit reliability using multi-angle imaging; deployed it as a mobile application using Flutter. The prototype was created in 20% less time than estimated. Collaborated with Google’s Flutter and Firebase teams alongside five teammates.</li>
              <li>Improved the accuracy of CNN to 86% in locating compromised regions of drill bit integrity.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Flutter, Firebase, FireStore, NodeJS, GCP, Python, TensorFlow, Auto-ML</li>
            </ul>
          </div>

          <!-- Advanced Technology Research Center -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>Advanced Technology Research Center - Stillwater, OK</strong></h4>
            <span>May 2018 - August 2019</span>
            <ul>
              <li>Enhanced and deployed Visual Inertial Odometry systems with 10% less complexity.</li>
              <li>Built a Jetson robot and deployed an ML-based hand follower with 20% less prototyping estimation time.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Raspberry Pi, Jetson Nano, Arduino, Roller/Global Shutter Cameras, Lidar, SLAM</li>
            </ul>
          </div>

          <!-- Mechatronic Research Lab (Nao, MRL-SPL) -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning & Research Engineer</strong></h3>
            <h4 class="company-name"><strong>Mechatronic Research Lab (Nao, MRL-SPL)</strong></h4>
            <span>August 2015 - May 2017</span>
            <ul>
              <li>Implemented a vision self-calibration method and optimized computer vision libraries for humanoid robots.</li>
              <li>Researched in a multidisciplinary team developing a classification system for EEG signals, enhancing BCI by 3%.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Proteus, OpenCV, C++, Neuroscience, Brain Anatomy, MATLAB, Machine Learning</li>
            </ul>
          </div>

          <!-- Center for Cyber-Physical Systems -->
          <div class="job">
            <h3 class="job-title"><strong>Virtual Reality Developer</strong></h3>
            <h4 class="company-name"><strong>Center for Cyber-Physical Systems - Stillwater, OK</strong></h4>
            <span>August 2018 - December 2019</span>
            <ul>
              <li>Designed CAD models and conducted simulations to explore lunar habitat architectures for NASA.</li>
              <li>Created an interactive VR platform focusing on the solar system to enhance learning for autistic children.</li>
              <li class="skills"><strong>Skills and Languages:</strong> SolidWorks, C#, VB, Unity, Virtual Reality, GitHub</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- Footer Section -->
      <div id="footer">
        Feel free to download this website's <a href="https://github.com/andyzeng/andyzeng.github.io">template</a>, just add a link back to my website. Inspired by <a href="https://jonbarron.info/">Jon's website</a>.
      </div>
    </div>

    <!-- Scripts -->
    <script>
      $(document).ready(function() {
        var $grid = $('.grid').isotope({
          itemSelector: '.list-item',
          layoutMode: 'fitRows',
          transitionDuration: '0.4s',
          stagger: 30,
          initLayout: true
        });

        // Filter on button click
        $('#filters').on('click', 'button', function() {
          var filterValue = $(this).attr('data-filter');
          localStorage.setItem('filterValue', filterValue);
          $grid.isotope({ filter: filterValue });

          // Toggle button active state
          $('#filters .button').removeClass('is-checked');
          $(this).addClass('is-checked');
        });

        // Retrieve cached filter state
        var savedFilter = localStorage.getItem('filterValue') || '.highlight';
        $grid.isotope({ filter: savedFilter });
        $('#filters .button[data-filter="' + savedFilter + '"]').addClass('is-checked');
      });

      function toggle_bio() {
        var bio = document.getElementById("more-bio");
        bio.style.display = bio.style.display === "none" ? "block" : "none";
      }
    </script>
  </body>
</html>

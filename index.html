<!DOCTYPE HTML>
<html>
  <head>
    <!-- Google Analytics Tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-STGLQW4BJX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-STGLQW4BJX');
    </script>

    <!-- Title -->
    <title>Araas (Habib) Boloorchi</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Isotope JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css2?family=Asap:wght@100;200;300;400;500;600;700&display=swap" rel="stylesheet">

    <!-- Additional Styles for Custom Formatting -->
    <style>
      .skills {
        color: grey;
      }
      .job-title {
        font-weight: bold;
      }
      .company-name {
        font-weight: bold;
      }

      /* Make highlight videos stack vertically and bigger */
      .list-item.highlight.previews {
        margin-bottom: 3rem;  /* More spacing at the bottom */
      }

      /* Center and size each video on its own line - BIGGER as requested */
      .list-item.highlight.previews video {
        display: block;
        margin: 1.5rem auto;    /* Center horizontally & add vertical spacing */
        width: 100%;           /* Take full width of container */
        max-width: 900px;     /* Increased from 700px to 900px */
        height: auto;
      }

      /* Extra styling for the new SightVoice highlight */
      .sightvoice {
        margin-bottom: 2rem;     /* Add extra space after SightVoice block */
      }
      .sightvoice img {
        display: block;          /* Make image a block-level element for centering */
        margin: 1rem auto 0;     /* Center horizontally and add top margin */
        max-width: 80%;          /* Increased from 70% to 80% */
        height: auto;
      }
      
      /* Resume styling */
      .resume-container {
        max-width: 900px;
        margin: 0 auto;
        font-family: 'Asap', sans-serif;
        line-height: 1.6;
      }
      
      .resume-section {
        margin-bottom: 2rem;
      }
      
      .resume-section h2 {
        border-bottom: 1px solid #ddd;
        padding-bottom: 0.5rem;
        margin-bottom: 1rem;
      }
      
      .resume-section h3 {
        margin-bottom: 0.3rem;
      }
      
      .resume-job {
        margin-bottom: 1.5rem;
      }
      
      .resume-date {
        color: #666;
        font-style: italic;
        margin-bottom: 0.5rem;
      }
      
      .resume-skills ul {
        display: flex;
        flex-wrap: wrap;
        gap: 0.5rem;
        padding: 0;
        list-style: none;
      }
      
      .resume-skills li {
        background-color: #f5f5f5;
        padding: 0.3rem 0.7rem;
        border-radius: 3px;
        font-size: 0.9rem;
      }
    </style>
  </head>

  <body id="body">
    <div id="main">
      <div id="intro">
        <div id="intro-text">
          <h1>Araas Boloorchi</h1>
          <p>
            I'm a Ph.D. candidate in Computer Science at Oklahoma State University. I am a researcher and machine learning expert focused on deep learning model architecture for industry and academia, specializing in computer vision, large language models, robotics, and IoT, with machine learning and data science expertise.
            <div id="more-bio" style="display: none;">
              <br>
              <p>Araas Boloorchi's journey in technology began in high school, where he focused on math and physics. His passion for innovation led him to the University of Science and Culture, where he pursued a degree in software engineering. In his first year, Araas began exploring the world of humanoid robots, utilizing mobile phones as a platform. This early experience sparked his interest in artificial intelligence and machine learning.

During his undergraduate years, Araas formed a team that participated in numerous competitions. One notable achievement was securing third place in an AI irregular gesture recognition competition using surveillance cameras. The challenge involved detecting fights, thrown objects, and left baggage. Araas's team also competed in various robotics contests, where he took on the role of a mentor, teaching his team machine learning techniques.

After earning his bachelor's degree, Araas pursued a master's degree at the University of Qazvin in Artificial Intelligence and Robotics, where he joined the MRL team in the Standard Platform League, focusing on NAO robots. His interest in cognitive science and the dream of robot's selfawareness led him to work in a cognitive systems lab, delving into EEG and cognitive science.

Araas's academic journey then took him to the United States, where he joined Oklahoma State University for a direct Ph.D. program. At OSU, he became a Graduate Teaching Assistant in his first year, sharing his knowledge and expertise with students. He then joined the Advanced Tech Research Center, focusing on Simultaneous Localization and Mapping (SLAM) and visual-inertial odometry. His work involved developing hardware with Raspberry Pi, cameras, and IMU, and was funded by the Air Force Institute.

Following his time at the ATRC, Araas worked in the Cyber-Physical Lab, where he utilized Unity and SolidWorks to create CAD models, virtual relity and Augmented reality. He also interned at Baker Hughes, a General Electric company, PwC, and Sanborn, gaining valuable industry experience.

Throughout his time at OSU, Araas continued to serve as a TA, sharing his knowledge in courses related to programming languages and computer science. He later joined the i-LEAD lab, focusing on explainable AI and computer vision. His research on visual-inertial odometry for low-cost devices culminated

in a published paper titled "Brain-Inspired Visual Odometry: Balancing Speed and Interpretability through a System of Systems Approach." This work exemplifies Araas's commitment to advancing AI technology while ensuring practical applications and interpretability.

Araas's diverse experiences have equipped him with a robust skill set in machine learning, robotics, computer vision, and software engineering. His journey reflects a continuous pursuit of knowledge and innovation, with a vision to bridge the gap between cutting-edge technology and real-world applications.</p>
            </div>
            <br>
            <a href="javascript:toggle_bio()">Formal Bio</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/Araas-Boloorchi">GitHub</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?user=0oXdUkAAAAAJ&hl=en">Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/Araas-boloorchi">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <br><br>
          </p>
        </div>
        <div id="intro-image">
          <img src="images/profile.jpg" alt="Araas Boloorchi">
        </div>
      </div>

      <!-- Filters Section - Added Resume button -->
      <div id="filters" class="button-group">
        <button class="button is-checked" data-filter=".highlight">Highlights</button>
        <button class="button" data-filter=".publication">Research</button>
        <button class="button" data-filter=".award">Awards & Scholarships</button>
        <button class="button" data-filter=".work-experience">Work Experience</button>
        <button class="button" data-filter=".resume">Resume</button>
      </div>

      <!-- Grid Section -->
      <div class="grid">
        <!-- Highlights Section -->
        <div class="list-item highlight description" data-category="highlight">
          When a robot moves or an AI project works something in my heart falls down:
        </div>

        <div class="list-item highlight previews" data-category="highlight">
          <video class="preview1" playsinline muted autoplay loop>
            <source src="images/VIO.mp4" type="video/mp4">
          </video>
          <video class="preview2" playsinline muted autoplay loop>
            <source src="images/Nao_Self_Calibration.mp4" type="video/mp4">
          </video>
          <video class="preview3" playsinline muted autoplay loop>
            <source src="images/Arm_Robot.mp4" type="video/mp4">
          </video>
        </div>

        <!-- NEW ITEM: SightVoice Highlight -->
        <div class="list-item highlight sightvoice" data-category="highlight">
          <h3>SightVoice</h3>
          <p>
            SightVoice is a platform that leverages computer vision and deep learning to assist visually impaired individuals in real-time, offering audio feedback on the user's surroundings and helping them navigate the world more independently.
          </p>
          <img src="images/WhatsApp Image 2025-01-21 at 22.56.56_9bb54812.jpg" alt="SightVoice Demo">
        </div>
        <!-- END NEW ITEM -->

        <!-- Publications Section -->
        <div class="list-item publication project-description" data-category="publication">
          <h3><a href="https://link.springer.com/article/10.1186/s42467-024-00016-5">Towards responsible AI: an implementable blueprint for integrating explainability and social-cognitive frameworks in AI systems</a></h3>
          <p>Rittika Shamsuddin, Araas Boloorchi, Pavan R. Gottimukkula</p>
        </div>
        <div class="list-item publication project-description" data-category="publication">
          <h3><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0oXdUkAAAAAJ&citation_for_view=0oXdUkAAAAAJ:9yKSN-GCB0IC">Brain-Inspired Visual Odometry: Balancing Speed and Interpretability through a System of Systems Approach</a></h3>
          <p>Araas Boloorchi Tabrizi, Christopher Crick</p>
        </div>
        
        <div class="list-item publication project-description" data-category="publication">
          <h3><a href="https://ieeexplore.ieee.org/abstract/document/10385640">Enhancing ProteinBERT: Integrating Intrinsically Disordered Proteins for Comprehensive Proteomic Predictions</a></h3>
          <p>Jewelle D. Stone, Araas Boloorchi Tabrizi, Rittika Shamsuddin</p>
        </div>

        <!-- Awards Section -->
        <div class="list-item award project-description" data-category="award">
          <ul>
            <li>
              <h3>Health AI Bias Summer School and Datathon Scholarship</h3>
              <p>August 2024</p>
            </li>
            <li>
              <h3>Scholarships for I-corps Workshops (Two Ideas)</h3>
              <p>June & July 2024</p>
            </li>
            <li>
              <h3>3-time Finalist - Business Plan Competition, Spears School of Business</h3>
              <p>Feb 2022, 2023, 2024</p>
            </li>
            <li>
              <h3>Champion - International Student Art Performance Competition at OSU</h3>
              <p>Nov 2022</p>
            </li>
            <li>
              <h3>Creativity, Innovation, and Entrepreneurship Scholarship</h3>
              <p>Dec 2021</p>
            </li>
            <li>
              <h3>1st Place - Innovative Idea in Automation and Transportation Competition</h3>
              <p>April 2018</p>
            </li>
            <li>
              <h3>1st Place - Open International Robotics League (Soccer) Technical Competition</h3>
              <p>April 2016</p>
            </li>
            <li>
              <h3>Finalist - Machine Vision for Irregular Gesture Recognition Competition, AUT Cop</h3> 
              <p>Sept 2013</p>
            </li>
          </ul>
        </div>

        <!-- Work Experience Section -->
        <div class="list-item work-experience project-description" data-category="work-experience">
          <h2>Work Experience</h2>
          
          <!-- ILead Laboratory -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>ILead Laboratory – Stillwater, OK</strong></h4>
            <span>May 2023 - May 2024</span>
            <ul>
              <li>Designed and developed an explainable deep model for describing visual charts with 87% precision via fine-tuned GPT-3.5, based on CNN, graph learning, and DNN, which we are submitting to the PAMI 2024 Journal.</li>
              <li>Improved 7% Breast Cancer Detection Datathon in X-ray in a multidisciplinary team with 9 members.</li>
              <li class="skills"><strong>Skills and Languages:</strong> PyTorch, TensorFlow, Keras, GNN, CNN, LLM, BERT, GAN, Fine-Tuning</li>
            </ul>
          </div>

          <!-- Sanborn -->
          <div class="job">
            <h3 class="job-title"><strong>Deep Learning and Computer Vision Engineer</strong></h3>
            <h4 class="company-name"><strong>Sanborn - Colorado Springs, CO</strong></h4>
            <span>May - August 2022</span>
            <ul>
              <li>Implemented and trained a new depth estimation approach with a 150 GB high-quality image dataset.</li>
              <li>Enhanced the CNN models to process full HD images with a 15% reduction in complexity.</li>
              <li class="skills"><strong>Skills and Languages:</strong> PyTorch, Keras, Python, CNN, Photogrammetry, Image Processing, Fine-Tuning</li>
            </ul>
          </div>

          <!-- PricewaterhouseCoopers (PwC) -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>PricewaterhouseCoopers (PwC) - Dallas, TX</strong></h4>
            <span>May - August 2020</span>
            <ul>
              <li>Re-engineered and tailored a data visualization tool in 20% less than estimated time with a team of 5.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Tableau, PySpark, Scala, AWS, Microsoft Azure, Jira, Random Forest, SAS</li>
            </ul>
          </div>

          <!-- General Electric -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Vision and Deep Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>General Electric - Oklahoma City, OK</strong></h4>
            <span>May - August 2019</span>
            <ul>
              <li>Developed a machine vision application to analyze drill bit reliability using multi-angle imaging; deployed it as a mobile application using Flutter. The prototype was created in 20% less time than estimated. Collaborated with Google's Flutter and Firebase teams alongside five teammates.</li>
              <li>Improved the accuracy of CNN to 86% in locating compromised regions of drill bit integrity.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Flutter, Firebase, FireStore, NodeJS, GCP, Python, TensorFlow, Auto-ML</li>
            </ul>
          </div>

          <!-- Advanced Technology Research Center -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning Engineer</strong></h3>
            <h4 class="company-name"><strong>Advanced Technology Research Center - Stillwater, OK</strong></h4>
            <span>May 2018 - August 2019</span>
            <ul>
              <li>Enhanced and deployed Visual Inertial Odometry systems with 10% less complexity.</li>
              <li>Built a Jetson robot and deployed an ML-based hand follower with 20% less prototyping estimation time.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Raspberry Pi, Jetson Nano, Arduino, Roller/Global Shutter Cameras, Lidar, SLAM</li>
            </ul>
          </div>

          <!-- Mechatronic Research Lab (Nao, MRL-SPL) -->
          <div class="job">
            <h3 class="job-title"><strong>Machine Learning & Research Engineer</strong></h3>
            <h4 class="company-name"><strong>Mechatronic Research Lab (Nao, MRL-SPL)</strong></h4>
            <span>August 2015 - May 2017</span>
            <ul>
              <li>Implemented a vision self-calibration method and optimized computer vision libraries for humanoid robots.</li>
              <li>Researched in a multidisciplinary team developing a classification system for EEG signals, enhancing BCI by 3%.</li>
              <li class="skills"><strong>Skills and Languages:</strong> Proteus, OpenCV, C++, Neuroscience, Brain Anatomy, MATLAB, Machine Learning</li>
            </ul>
          </div>

          <!-- Center for Cyber-Physical Systems -->
          <div class="job">
            <h3 class="job-title"><strong>Virtual Reality Developer</strong></h3>
            <h4 class="company-name"><strong>Center for Cyber-Physical Systems - Stillwater, OK</strong></h4>
            <span>August 2018 - December 2019</span>
            <ul>
              <li>Designed CAD models and conducted simulations to explore lunar habitat architectures for NASA.</li>
              <li>Created an interactive VR platform focusing on the solar system to enhance learning for autistic children.</li>
              <li class="skills"><strong>Skills and Languages:</strong> SolidWorks, C#, VB, Unity, Virtual Reality, GitHub</li>
            </ul>
          </div>
        </div>
        
        <!-- NEW RESUME SECTION -->
        <div class="list-item resume project-description" data-category="resume">
          <div class="resume-container">
            <div class="resume-section">
              <h2>SUMMARY</h2>
              <p>Machine-Learning engineer with Ph.D. in Computer Science and 5+ years translating research into production. Specialized in retrieval-augmented generation, explainable computer vision, and LLM-powered products. Experienced leading cross-functional teams from ideation to launch in startup and enterprise settings.</p>
            </div>
            
            <div class="resume-section">
              <h2>EDUCATION</h2>
              <h3>Oklahoma State University</h3>
              <p>Ph.D. and M.S., Computer Science | May 2025</p>
              <p><em>Explainable AI in Visual Odometry and Generative AI For Autonomous Drones</em></p>
            </div>
            
            <div class="resume-section">
              <h2>PROFESSIONAL EXPERIENCE</h2>
              
              <div class="resume-job">
                <h3>Machine Learning Engineer | Catchup AI, San Francisco, CA</h3>
                <div class="resume-date">Jan 2024 - Present</div>
                <ul>
                  <li>Architected an agentic RAG communication assistant for managers, reducing manual meeting-summarization time by 60%+.</li>
                  <li>Led a 4-engineer ML team from concept to MVP in 12 weeks, securing initial customer pilots.</li>
                  <li>Built prompt-driven sentiment pipeline on Jira, Slack & Zoom JSON, boosting precision from 0.71 to 0.86.</li>
                  <li>Implemented PyTorch GNN modeling company social graph, improving recommendation accuracy 22%.</li>
                </ul>
              </div>
              
              <div class="resume-job">
                <h3>Machine Learning Engineer | ILead Lab, Stillwater, OK</h3>
                <div class="resume-date">May 2023 - Jan 2024</div>
                <ul>
                  <li>Developed CNN to analyze statistical charts with 94% precision.</li>
                  <li>Designed Gen-AI explanation module that generated insights with 91% user-rated clarity.</li>
                  <li>Enhanced YOLO-based Keras model, raising breast-cancer detection recall 7%.</li>
                </ul>
              </div>
            </div>
            
            <div class="resume-section">
              <h2>ADDITIONAL EXPERIENCE</h2>
              
              <div class="resume-job">
                <h3>Computer Vision Engineer Intern | Sanborn, Colorado Springs, CO</h3>
                <div class="resume-date">May 2022 - Aug 2022</div>
                <ul>
                  <li>Fine-tuned TensorFlow depth-estimation model, cutting inference latency 30%.</li>
                  <li>Built OpenCV pipeline for stereo AV data, boosting downstream accuracy 15%.</li>
                </ul>
              </div>
              
              <div class="resume-job">
                <h3>Data Scientist Intern | PwC, Dallas, TX</h3>
                <div class="resume-date">May 2021 - Aug 2021</div>
                <ul>
                  <li>Created modular Python data-visualizer replacing Tableau, saving $50k license costs.</li>
                </ul>
              </div>
              
              <div class="resume-job">
                <h3>Machine Learning Engineer Intern | General Electric, Oklahoma City, OK</h3>
                <div class="resume-date">May 2020 - Aug 2020</div>
                <ul>
                  <li>Shipped mobile app that predicts oil-drill-bit reliability from photos, achieving 88% F1.</li>
                </ul>
              </div>
            </div>
            
            <div class="resume-section">
              <h2>PROJECTS</h2>
              
              <div class="resume-job">
                <h3>Visually Impaired Assistant Headband | Entrepreneurship Project</h3>
                <div class="resume-date">Jan 2025</div>
                <p>Designed and crafted a functioning prototype to give blind person awareness by voice and won many Business plan competitions.</p>
              </div>
              
              <div class="resume-job">
                <h3>AI + Global Health | 24 Hours Hackathon, San Francisco, CA</h3>
                <div class="resume-date">Dec 2024</div>
                <p>Launched prototype for blinds to alarm for obstacle recognition via webcam and apple vision pro.</p>
              </div>
              
              <div class="resume-job">
                <h3>Voice & Video | 12 Hours Hackathon, San Francisco, CA</h3>
                <div class="resume-date">Dec 2024</div>
                <p>Established a web app Agentic avatar to ask customers need and find it based on reviews.</p>
              </div>
              
              <div class="resume-job">
                <h3>HeyGen AI Avatar | 12 Hours Hackathon, San Francisco, CA</h3>
                <div class="resume-date">Dec 2024</div>
                <p>Modified a manager avatar agent able to meet with employees and report summaries using OpenAI.</p>
              </div>
              
              <div class="resume-job">
                <h3>Autonomous Drone Navigation | Advanced Tech and Research Center, Stillwater, OK</h3>
                <div class="resume-date">Dec 2019</div>
                <p>Realized conceptual method to real-time navigation device and Visual Inertial Odometry software.</p>
              </div>
            </div>
            
            <div class="resume-section">
              <h2>PUBLICATIONS</h2>
              
              <div class="resume-job">
                <h3>Springer Nature Journal | AI Perspectives & Advances</h3>
                <div class="resume-date">Jan 2025</div>
                <p>Towards responsible AI: an implementable blueprint for integrating explainability and social-cognitive frameworks in AI systems.</p>
              </div>
              
              <div class="resume-job">
                <h3>IEEE | International Conference on Computational Science and Computational Intelligence</h3>
                <div class="resume-date">Dec 2023</div>
                <p>Brain-Inspired Visual Odometry: Balancing Speed and Interpretability Through a System of Systems Approach.</p>
              </div>
              
              <div class="resume-job">
                <h3>IEEE | International Conference on Bioinformatics and Biomedicine</h3>
                <div class="resume-date">Dec 2023</div>
                <p>Enhancing ProteinBERT: Integrating Intrinsically Disordered Proteins for Comprehensive Proteomic Predictions.</p>
              </div>
            </div>
            
            <div class="resume-section">
              <h2>AWARDS</h2>
              
              <div class="resume-job">
                <h3>Hackathons and Datathon | AI Based Applications, San Francisco, CA</h3>
                <ul>
                  <li>2nd Place, ACM Hackathon (Apr 2025)</li>
                  <li>1st place for Teamwork, awarded for creating a Visual Assistant for blinds, AI+ Global Health (Dec 2024)</li>
                  <li>Top-five Finalist and 1st in 'Unified.to' platform, Startup Hackathon for Video and Sound (Dec 2024)</li>
                  <li>Health AI Bias Summer School and Datathon Scholarship (HITI Lab) (Aug 2024)</li>
                </ul>
              </div>
              
              <div class="resume-job">
                <h3>Innovation and Entrepreneurship | Oklahoma State University, Stillwater, OK</h3>
                <ul>
                  <li>I-Corps Workshop Scholarships for Innovative Projects (Jun - Jul 2024)</li>
                  <li>Four-time Finalist, Business Plan Competition (Feb 2022 - Feb 2025)</li>
                  <li>3rd Place, Business Plan Competition (Feb 2022)</li>
                  <li>Creativity, Innovation, and Entrepreneurship Scholarship (Jan 2022)</li>
                </ul>
              </div>
            </div>
            
            <div class="resume-section">
              <h2>SKILLS</h2>
              
              <div class="resume-skills">
                <h3>AI Foundation</h3>
                <p>General Machine Learning, GNN (Graph), CNN, GCN, Transformers, XGBoost</p>
                
                <h3>LLM</h3>
                <p>LlamaIndex, Prompt Engineering, RAG, Agentic, Lang Chain, OpenAI API</p>
                
                <h3>Computer Vision</h3>
                <p>Photogrammetry, 3D Computer Vision, Depth Estimation, SLAM, UAV Navigation</p>
                
                <h3>Robotics</h3>
                <p>Sensor Fusion, Kalman Filter, Motion Planning, Reinforcement Learning, Jetson Nano</p>
                
                <h3>Programming & Scripting</h3>
                <p>Python, Java, C, C++, Dart, Swift, Kotlin, Scala, MATLAB, React</p>
                
                <h3>Frameworks & Libraries</h3>
                <p>PyTorch, TensorFlow, Keras, GCP, AWS, Django, ROS, OpenCV</p>
                
                <h3>Professional Skills</h3>
                <p>Teamwork in a Cross-Functional Environment, Agile Software Development, Communication, Critical Thinking Skills, Data Visualization and Storytelling, Research</p>
              </div>
            </div>
          </div>
        </div>
        <!-- END NEW RESUME SECTION -->
      </div>

      <!-- Footer Section -->
      <div id="footer">
        Feel free to download this website's <a href="https://github.com/andyzeng/andyzeng.github.io">template</a>, just add a link back to my website. Inspired by <a href="https://jonbarron.info/">Jon's website</a>.
      </div>
    </div>

    <!-- Scripts -->
    <script>
      $(document).ready(function() {
        var $grid = $('.grid').isotope({
          itemSelector: '.list-item',
          layoutMode: 'fitRows',
          transitionDuration: '0.4s',
          stagger: 30,
          initLayout: true
        });

        // Filter on button click
        $('#filters').on('click', 'button', function() {
          var filterValue = $(this).attr('data-filter');
          localStorage.setItem('filterValue', filterValue);
          $grid.isotope({ filter: filterValue });

          // Toggle button active state
          $('#filters .button').removeClass('is-checked');
          $(this).addClass('is-checked');
        });

        // Retrieve cached filter state
        var savedFilter = localStorage.getItem('filterValue') || '.highlight';
        $grid.isotope({ filter: savedFilter });
        $('#filters .button[data-filter="' + savedFilter + '"]').addClass('is-checked');
      });

      function toggle_bio() {
        var bio = document.getElementById("more-bio");
        bio.style.display = bio.style.display === "none" ? "block" : "none";
      }
    </script>
  </body>
</html>
